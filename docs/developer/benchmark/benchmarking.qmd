---
title: "Profiling and Performance"
format: html
---

This document describes the benchmarking infrastructure for Neuralyzer, including how to create benchmarks, run them, and analyze performance using various profiling tools.

## Quick Start

``` bash
# Build with benchmarks enabled (they're on by default)
cmake --preset linux-clang-release -DENABLE_BENCHMARK=ON
cmake --build --preset linux-clang-release

# Run all benchmarks
cd out/build/Clang/Release/benchmark
./benchmark_MaskArea

# Run specific benchmarks with filtering
./benchmark_MaskArea --benchmark_filter=Pipeline

# Run with different output formats
./benchmark_MaskArea --benchmark_format=json > results.json
./benchmark_MaskArea --benchmark_format=csv > results.csv
```

## Architecture

### CMake Infrastructure

The benchmarking system is built on `cmake/BenchmarkUtils.cmake`, which provides:

-   `add_selective_benchmark()` - Create individual benchmark executables
-   `configure_benchmark_for_profiling()` - Add profiling tool support
-   `print_benchmark_summary()` - Display configuration summary

Each benchmark can be individually enabled/disabled via CMake options:

``` bash
# Disable a specific benchmark
cmake -DBENCHMARK_MASK_AREA=OFF ..

# Only build specific benchmarks
cmake -DBENCHMARK_MASK_AREA=ON -DBENCHMARK_OTHER=OFF ..
```

### Test Data Fixtures

`benchmark/fixtures/BenchmarkFixtures.hpp` provides fixtures for generating realistic test data:

-   `MaskDataFixture` - Generate MaskData with configurable properties
-   `LineDataFixture` - Generate LineData for curve/line benchmarks
-   `PointDataFixture` - Generate PointData for point-based benchmarks

Presets are available for common scenarios: - `Presets::SmallMaskData()` - Quick iteration (10 frames) - `Presets::MediumMaskData()` - Realistic testing (100 frames) - `Presets::LargeMaskData()` - Stress testing (1000 frames) - `Presets::SparseMaskData()` - Few masks, large time gaps - `Presets::DenseMaskData()` - Many small masks per frame

Example usage:

``` cpp
#include "fixtures/BenchmarkFixtures.hpp"

BENCHMARK_F(MyBenchmark, TestCase)(benchmark::State& state) {
    auto fixture = MaskDataFixture(Presets::MediumMaskData());
    auto mask_data = fixture.generate();
    
    for (auto _ : state) {
        // Benchmark code here
    }
}
```

## Creating New Benchmarks

### 1. Create Benchmark Source File

Create `benchmark/MyFeature.benchmark.cpp`:

``` cpp
#include "fixtures/BenchmarkFixtures.hpp"
#include <benchmark/benchmark.h>

// Simple function benchmark
static void BM_MyFunction(benchmark::State& state) {
    // Setup
    auto data = setupTestData();
    
    for (auto _ : state) {
        auto result = myFunction(data);
        benchmark::DoNotOptimize(result);
    }
}
BENCHMARK(BM_MyFunction);

// Fixture-based benchmark
class MyFeatureBenchmark : public benchmark::Fixture {
public:
    void SetUp(benchmark::State const& state) override {
        // Generate test data once
        test_data_ = generateData();
    }
    
protected:
    std::shared_ptr<DataType> test_data_;
};

BENCHMARK_F(MyFeatureBenchmark, TestCase)(benchmark::State& state) {
    for (auto _ : state) {
        auto result = process(test_data_);
        benchmark::DoNotOptimize(result);
    }
}

BENCHMARK_MAIN();
```

### 2. Register in CMake

Add to `benchmark/CMakeLists.txt`:

``` cmake
add_selective_benchmark(
    NAME MyFeature
    SOURCES 
        MyFeature.benchmark.cpp
    LINK_LIBRARIES 
        DataManager
        MyFeatureLib
    DEFAULT ON
)

# Optional: Enable profiling support
if(TARGET benchmark_MyFeature)
    configure_benchmark_for_profiling(
        TARGET benchmark_MyFeature
        ENABLE_PERF ON
        ENABLE_HEAPTRACK ON
        GENERATE_ASM ON
    )
endif()
```

### 3. Build and Run

``` bash
cmake --build --preset linux-clang-release
./out/build/Clang/Release/benchmark/benchmark_MyFeature
```

## Google Benchmark Features

### Parameterized Benchmarks

Test with different input sizes:

``` cpp
BENCHMARK(BM_MyFunction)
    ->Arg(100)
    ->Arg(1000)
    ->Arg(10000)
    ->Unit(benchmark::kMillisecond);

// Or use ranges
BENCHMARK(BM_MyFunction)
    ->Range(8, 8<<10)  // 8 to 8192, powers of 2
    ->RangeMultiplier(2);
```

### Fixtures with Parameters

``` cpp
BENCHMARK_F(MyBenchmark, TestCase)(benchmark::State& state) {
    size_t size = state.range(0);
    // Use size parameter
}
BENCHMARK_REGISTER_F(MyBenchmark, TestCase)
    ->DenseRange(0, 4)  // Parameters 0, 1, 2, 3, 4
    ->Unit(benchmark::kMicrosecond);
```

### Custom Counters

Track additional metrics:

``` cpp
for (auto _ : state) {
    auto result = myFunction(data);
    state.counters["items_processed"] = data.size();
    state.counters["bytes_processed"] = data.size() * sizeof(Item);
}

state.SetItemsProcessed(state.iterations() * data.size());
state.SetBytesProcessed(state.iterations() * data.size() * sizeof(Item));
```

## Performance Analysis Tools

### 1. Perf (CPU Profiling)

Profile CPU usage and generate call graphs:

``` bash
# Record profile data
perf record -g ./benchmark_MaskArea --benchmark_filter=Pipeline

# View interactive report
perf report

# Generate flamegraph
perf script | stackcollapse-perf.pl | flamegraph.pl > flame.svg

# View specific functions
perf annotate functionName

# Show hot spots
perf top
```

Key perf options: - `-g` - Enable call-graph (stack trace) recording - `-e cycles` - Profile CPU cycles - `-e cache-misses` - Profile cache misses - `--call-graph dwarf` - Use DWARF for more accurate call graphs

### 2. Heaptrack (Memory Profiling)

Analyze memory allocation patterns:

``` bash
# Run with heaptrack
heaptrack ./benchmark_MaskArea

# View results in GUI
heaptrack_gui heaptrack.benchmark_MaskArea.*.gz

# View results in terminal
heaptrack_print heaptrack.benchmark_MaskArea.*.gz
```

What heaptrack shows: - Total memory allocated - Peak memory usage - Number of allocations - Call stacks for allocations - Memory leaks - Temporary allocations

### 3. Valgrind Cachegrind (Cache Analysis)

Analyze cache behavior:

``` bash
# Run cachegrind
valgrind --tool=cachegrind ./benchmark_MaskArea --benchmark_filter=CacheBehavior

# Visualize results
cg_annotate cachegrind.out.<pid>

# Interactive visualization
kcachegrind cachegrind.out.<pid>
```

Metrics provided: - L1/L2/L3 cache hits/misses - Instruction cache behavior - Data cache behavior - Branch prediction statistics

### 4. Assembly Inspection

View generated assembly for optimization:

``` bash
# Method 1: objdump
objdump -d -C -S ./benchmark_MaskArea | less

# Search for specific function
objdump -d -C -S ./benchmark_MaskArea | grep -A 50 "calculateMaskArea"

# Method 2: During compilation (if GENERATE_ASM=ON)
# Assembly files (.s) generated alongside object files
find . -name "*.s" | xargs less
```

What to look for: - Loop vectorization (SIMD instructions) - Unnecessary branches - Memory access patterns - Inlining decisions - Register usage

### 5. Time Command (Quick Stats)

Get quick overview of resource usage:

``` bash
/usr/bin/time -v ./benchmark_MaskArea

# Key metrics:
# - Maximum resident set size (peak memory)
# - Page faults (major = disk I/O, minor = memory)
# - Context switches
# - CPU percentage
```

### 6. Clang Build Time Analysis

If built with `-DENABLE_TIME_TRACE=ON`:

``` bash
# View compilation time breakdown
ClangBuildAnalyzer --all build_trace build_results.bin
ClangBuildAnalyzer --analyze build_results.bin
```

## AnalogTimeSeries Loading Performance

We benchmarked the loading of binary data into `AnalogTimeSeries` to identify performance bottlenecks and evaluate optimizations.
The benchmark compares different loading strategies for the *same* underlying data (10MB binary file).

### Results (10MB Data)

| Scenario | Time | Speed | Slowdown vs Best Case |
| :--- | :--- | :--- | :--- |
| **Best Case (Raw Read)** | ~2.5 ms | ~4.0 GB/s | 1.0x |
| **Multi Channel** (True 32ch) | ~17 ms | ~580 MB/s | ~6.8x |
| **Fake Multi Channel** (1ch file as 32ch) | ~17 ms | ~580 MB/s | ~6.8x |
| **Single Channel** (Optimized) | ~62.5 ms | ~160 MB/s | ~25x |
| **Single Channel** (Baseline) | ~70 ms | ~140 MB/s | ~28x |

### Analysis

1.  **Optimization**: The optimized single-channel loader (using chunked reading and direct conversion) provides a ~12% speedup over the baseline.
2.  **Apples-to-Apples Comparison**:
    *   To understand why Multi-Channel is so much faster, we added a "Fake Multi Channel" benchmark that loads the *single-channel file* using the *multi-channel loader logic* (splitting it into 32 arbitrary channels).
    *   **Key Finding**: The "Fake Multi Channel" load time (~17ms) matches the True Multi Channel time. This proves that **splitting the data into 32 smaller vectors is inherently faster than loading it into 1 large vector**.
3.  **Cause of Slowdown**:
    *   The single-channel loader must write to one large contiguous `std::vector<float>` (20MB). This likely causes significant cache thrashing and memory management overhead compared to writing to 32 small vectors (which stay hot in L2/L3 cache during processing).
    *   Parallelization (OpenMP) was attempted on the single-channel loader but resulted in slower performance (~80ms), suggesting memory bandwidth or thread contention is the bottleneck for the single-vector write pattern.

### Conclusion

The "slowdown" in single-channel loading is a structural consequence of managing large contiguous memory blocks versus smaller, cache-friendly blocks. While the optimized loader provides a tangible improvement (12%), achieving parity with multi-channel loading would likely require architectural changes to `AnalogTimeSeries` to support segmented/tiled storage instead of a single flat vector.

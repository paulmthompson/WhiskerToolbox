---
title: "AnalogTimeSeries View Storage Performance Analysis"
format: html
---

This document describes the performance analysis of using `AnalogTimeSeries` views vs. raw vectors for line plot generation, a common operation in neural data visualization.

## Background

A line plot displays continuous analog signals (e.g., LFP, EMG) aligned to trial events. For each alignment event, we need to:

1. Extract samples within a time window around the alignment point
2. Transform the data for GPU rendering (populate vertex buffers)

We compared two approaches:

1. **Baseline (Raw Vectors)**: Use `std::vector<std::vector<float>>` for windowed signals
2. **View-Based**: Use `std::vector<shared_ptr<AnalogTimeSeries>>` with view storage backend

## Key Difference from DigitalEventSeries Views

Unlike `DigitalEventSeries` views which use index indirection (each access requires looking up an index, then accessing the source), `AnalogTimeSeries` views provide **contiguous span access** because:

- `ViewAnalogDataStorage` stores start/end offsets into the source `VectorAnalogDataStorage`
- The source data is always contiguous in memory
- Views can return `std::span<float const>` directly pointing into source memory

This means iteration performance is essentially identical to raw vectors once views are created.

## Benchmark Configuration

```
Total samples:       1,000,000 (full analog time series)
Alignment events:      1,000   (number of trials/windows)
Window size:           1,000   (±500 samples around each alignment)
Samples per window:    1,000   (contiguous block)
```

## Results Summary

### Full Pipeline Performance

| Approach | Time (µs) | Relative |
|----------|----------|----------|
| Baseline (Raw Vectors) | 2,629 | 1.0x |
| View-Based (Span) | 2,058 | **0.78x (faster!)** |

### Phase Breakdown

| Phase | Baseline (µs) | View-Based (µs) | Ratio |
|-------|---------------|-----------------|-------|
| Window/View Creation | 310 | 181 | **0.58x (faster!)** |
| Iteration Only (Span) | 1,069 | 1,078 | 1.01x |
| Iteration Only (Iterator) | 1,069 | 3,220 | 3.0x |

## Key Insights

### View Creation is Now Faster Than Copying (0.58x)

After optimizing time storage creation, views are now **faster to create** than raw vector copies:

| Operation | Cost |
|-----------|------|
| Baseline: Copy 1000 floats × 1000 windows | ~310 µs (memcpy ~4MB) |
| View: Create 1000 views with O(1) time storage | ~181 µs |

The optimization detects when the source has `DenseTimeIndexStorage` (the common case for uniformly sampled data) and creates the view's time storage as a new dense range in O(1) instead of materializing a vector in O(n):

```cpp
auto const* dense_source = dynamic_cast<DenseTimeIndexStorage const*>(source->_time_storage.get());
if (dense_source != nullptr) {
    // O(1): Just store new start index and count
    TimeFrameIndex view_start = dense_source->getTimeFrameIndexAt(start_idx);
    view_time_storage = TimeIndexStorageFactory::createDense(view_start, view_count);
} else {
    // O(n): Sparse case - must materialize time indices
    // ... fallback to vector construction
}
```

### Iteration Performance is Identical with Span Access (1.01x)

Once views are created, span-based iteration matches raw vector performance exactly:

```cpp
// Both compile to essentially the same code
for (auto val : vector) { sum += val; }
for (auto val : view->getAnalogTimeSeries()) { sum += val; }
```

This is because `ViewAnalogDataStorage::getSpanImpl()` returns a span pointing directly into the source memory.

### Iterator Access Has 3x Overhead

Using `elements()` iterator instead of span access adds overhead:

```cpp
// This is 3x slower due to virtual dispatch and pair construction
for (auto const& [time, value] : view->elements()) { sum += value; }
```

## Architecture: Zero-Copy View Storage

### How It Works

The `DataStorageWrapper` uses `shared_ptr` internally (fixed from previous `unique_ptr` bug):

```cpp
class DataStorageWrapper {
    std::shared_ptr<StorageConcept> _impl;  // Shared ownership of storage
};
```

When creating a view, we use the **aliasing constructor** of `shared_ptr`:

```cpp
std::shared_ptr<VectorAnalogDataStorage const> getSharedVectorStorage() const {
    if (auto vector_model = std::dynamic_pointer_cast<StorageModel<VectorAnalogDataStorage> const>(_impl)) {
        // Aliasing constructor: shares ownership with _impl but points to inner storage
        return std::shared_ptr<VectorAnalogDataStorage const>(vector_model, &vector_model->_storage);
    }
    return nullptr;
}
```

### View Storage Structure

Each view consists of:

1. A `shared_ptr` to the source's `VectorAnalogDataStorage` (shared among all views)
2. Start and end indices defining the view window
3. A separate `TimeIndexStorage` for the view's time indices

```
Source (1M samples)
    └── _data_storage (DataStorageWrapper)
            └── _impl (shared_ptr<StorageConcept>)
                    └── VectorAnalogDataStorage with float* data

View 1 (window around alignment 0)      ──┐
    └── ViewAnalogDataStorage            │
        ├── _source (shared_ptr) ────────┼── All share same source
        ├── _start_index = 1000          │
        └── _end_index = 2000            │
                                         │
View 2 (window around alignment 1)      ──┤
    └── ViewAnalogDataStorage            │
        ├── _source (shared_ptr) ────────┘
        ├── _start_index = 5500
        └── _end_index = 6500
...
```

## Historical Note: The unique_ptr Bug

The original `DataStorageWrapper` implementation used `std::unique_ptr<StorageConcept>`:

```cpp
// BUG: unique_ptr prevented sharing - had to copy entire storage for views!
std::unique_ptr<StorageConcept> _impl;
```

This was the same bug found in `DigitalEventStorageWrapper`. The fix changed to `shared_ptr` to enable:

- Zero-copy view creation via aliasing constructor
- Correct lifetime management (source outlives views)
- Multiple views sharing one underlying storage

## When to Use Views vs. Raw Vectors

**Views are now the preferred approach for most use cases:**

- Zero-copy data sharing (no memcpy)
- Faster creation than raw vector extraction for dense time storage
- Integration with TimeFrame conversion system
- Chaining with lazy transforms
- Full `AnalogTimeSeries` API (getAtTime, elements, etc.)

**Raw vectors may still be preferred for:**

- Sparse time storage sources (where O(n) time materialization is required)
- When you need to mutate the extracted data
- Integration with external libraries expecting `std::vector<float>`

## Access Pattern Recommendations

| Access Pattern | Method | Relative Speed |
|----------------|--------|----------------|
| **Best** | `getAnalogTimeSeries()` → span | 1.0x |
| Good | `getDataInTimeFrameIndexRange()` → span | 1.0x |
| Slower | `elements()` iterator | 3.0x |
| Slowest | `getAtTime()` per-sample | 10x+ |

## Running the Benchmark

```bash
# Build
cmake --preset linux-clang-release -DENABLE_BENCHMARK=ON
cmake --build --preset linux-clang-release --target benchmark_LinePlotViews

# Run all tests
./out/build/Clang/Release/benchmark/benchmark_LinePlotViews

# Run specific tests
./benchmark_LinePlotViews --benchmark_filter="FullPipeline"
./benchmark_LinePlotViews --benchmark_filter="IterationOnly"

# Cache analysis
perf stat -e cache-references,cache-misses,L1-dcache-load-misses \
    ./benchmark_LinePlotViews --benchmark_filter="IterationOnly"
```

## Conclusion

The view-based approach using `AnalogTimeSeries` achieves true zero-copy data sharing via `shared_ptr` with aliasing constructor. With the optimized dense time storage creation, **views are now faster than raw vector extraction** for the common case of uniformly sampled data.

| Metric | Baseline | View-Based | Winner |
|--------|----------|------------|--------|
| Creation | 310 µs | 181 µs | **Views (1.7x faster)** |
| Full Pipeline | 2,629 µs | 2,058 µs | **Views (1.3x faster)** |
| Iteration (Span) | 1,069 µs | 1,078 µs | Tie |

The key optimizations that made this possible:

1. **shared_ptr for storage** (bug fix): Enables zero-copy view creation via aliasing constructor
2. **O(1) dense time storage**: Detects `DenseTimeIndexStorage` and creates view time storage as `createDense(start, count)` instead of materializing an O(n) vector

**Key recommendation**: Use `createView()` for windowed access to `AnalogTimeSeries` data. Always use `getAnalogTimeSeries()` or `getDataInTimeFrameIndexRange()` for span-based iteration rather than `elements()` iterator.

---
title: "DigitalEventSeries View Storage Performance Analysis"
format: html
---

This document describes the performance analysis of using `DigitalEventSeries` views vs. raw vectors for raster plot generation, a common operation in neural data visualization.

## Background

A raster plot displays events (e.g., neural spikes) aligned to trial events (e.g., stimulus onsets). For each alignment event, we need to:

1. Extract events within a time window around the alignment point
2. Transform the data for GPU rendering (populate vertex buffers)

We compared three approaches:

1. **Baseline (Raw Vectors)**: Use `std::vector<std::vector<TimeFrameIndex>>` for windowed events
2. **View-Based (Manual)**: Use `std::vector<std::shared_ptr<DigitalEventSeries>>` with view storage, creating views in a manual loop
3. **Gather-Based**: Use `GatherResult<DigitalEventSeries>` via the `gather()` utility function

## Benchmark Configuration

```
Raster events:     100,000 (total events to filter)
Alignment events:    1,000 (number of trials/windows)
Window size:         1,000 (±500 around each alignment)
Expected events/window: ~100 (based on density)
```

## Results Summary

### Full Pipeline Performance

| Approach | Time (µs) | Relative |
|----------|----------|----------|
| Baseline (Raw Vectors) | 368 | 1.0x |
| View-Based (Manual) | 1,229 | 3.3x slower |
| Gather-Based | 1,229 | 3.3x slower |

The `gather()` utility matches the performance of manual view creation while providing a cleaner API.

### Phase Breakdown

| Phase | Baseline (µs) | View-Based (µs) | Gather (µs) | Ratio (View/Baseline) |
|-------|---------------|-----------------|-------------|----------------------|
| Window/View Creation | 182 | 1,096 | 984 | 5.4x |
| Buffer Population | 175 | 215 | 215 | 1.2x |
| Iteration Only | 17.5 | 29.9 | 27.2 | 1.6x |

**Notable**: `gather()` is ~10% faster than manual view creation due to better reservation and single-pass interval iteration.

### Transform Helper Performance

The `GatherResult::transform()` method enables efficient per-trial computations:

| Operation | Time (µs) |
|-----------|-----------|
| `gathered.transform([](v) { return v->size(); })` | 4.17 |

This is very fast for computing statistics like spike counts across 1,000 trials.

## Architecture: Zero-Copy View Storage

### How It Works

The `DigitalEventStorageWrapper` uses a type-erased `shared_ptr` design that enables true zero-copy view creation:

```cpp
class DigitalEventStorageWrapper {
    std::shared_ptr<StorageConcept> _impl;  // Shared ownership of storage
};
```

When creating a view, we use the **aliasing constructor** of `shared_ptr`:

```cpp
std::shared_ptr<OwningDigitalEventStorage const> getSharedOwningStorage() const {
    if (auto owning_model = std::dynamic_pointer_cast<StorageModel<OwningDigitalEventStorage> const>(_impl)) {
        // Aliasing constructor: shares ownership with _impl but points to inner storage
        return std::shared_ptr<OwningDigitalEventStorage const>(owning_model, &owning_model->_storage);
    }
    return nullptr;
}
```

This allows:

- **Zero data copying**: The returned `shared_ptr` points directly into the existing storage
- **Correct lifetime management**: The source storage stays alive as long as any view exists
- **Shared references**: Multiple views from the same source share one underlying storage

### View Storage Structure

Each view consists of:

1. A `shared_ptr` to the source's owning storage (shared among all views)
2. A vector of indices specifying which events are visible
3. Time range bounds for filtering

```
Source (100K events)
    └── _storage (DigitalEventStorageWrapper)
            └── _impl (shared_ptr<StorageConcept>)
                    └── OwningDigitalEventStorage with actual data

View 1 (window around alignment 0)      ──┐
View 2 (window around alignment 1)      ──┼── All share same source via shared_ptr
...                                       │
View 1000 (window around alignment 999) ──┘
```

## Performance Characteristics

### View Creation Overhead (5.6x)

Creating 1,000 views takes ~1ms. This overhead comes from:

| Factor | Cost |
|--------|------|
| `shared_ptr` allocation per view | ~400ns each |
| `ViewDigitalEventStorage` setup | Index vector allocation |
| `filterByTimeRange()` | Binary search + index copy |
| Type erasure wrapper construction | `StorageModel` allocation |

### Iteration Overhead (1.6x)

Once views are created, iterating through them is reasonably efficient:

| Factor | Baseline | View-Based | Impact |
|--------|----------|------------|--------|
| **Access Pattern** | `events[i]` | `source->getEvent(indices[i])` | Double indirection |
| **Data Layout** | Contiguous | Index + data arrays | Reduced cache locality |
| **Virtual Dispatch** | None | Through type erasure | Minimal (~1-2ns/call) |

The 1.6x iteration overhead is acceptable for most use cases.

## Scalability Analysis

| Alignments | Baseline (µs) | View-Based (µs) | Gather (µs) | Ratio (View) | Ratio (Gather) |
|------------|---------------|-----------------|-------------|--------------|----------------|
| 100 | 31 | 110 | 120 | 3.5x | 3.9x |
| 500 | 186 | 575 | 588 | 3.1x | 3.2x |
| 1,000 | 367 | 1,204 | 1,169 | 3.3x | 3.2x |
| 2,000 | 720 | 2,530 | 2,491 | 3.5x | 3.5x |
| 5,000 | 1,926 | 7,105 | 6,573 | 3.7x | 3.4x |

Both view-based approaches scale linearly with alignment count. At higher alignment counts (5000), `gather()` is ~8% faster than manual view creation.

## Historical Note: The Copy Bug

An earlier implementation had a critical bug causing ~5000x slowdown:

```cpp
// BUG: This copied the entire storage for every view!
auto view_storage = ViewDigitalEventStorage{
    std::make_shared<OwningDigitalEventStorage const>(*src_owning)  // COPIES!
};
```

With 1,000 views of 100K events, this meant 100 million unnecessary event copies. The fix was changing `DigitalEventStorageWrapper` from `unique_ptr` to `shared_ptr` with aliasing constructor support.

## When to Use Each Approach

### Raw Vectors

**Best for:**

- High-frequency rendering loops (60+ FPS animation)
- Simple iteration without entity tracking
- When data is already filtered at load time
- Performance-critical hot paths

### gather() with GatherResult

**Best for:**

- Trial-aligned analysis (raster plots, PSTHs, etc.)
- When you need source tracking and interval metadata
- Applying functions across all trials via `transform()`
- Clean, self-documenting code with no performance penalty vs. manual views

```cpp
// Example: Raster plot with gather()
auto spikes = dm->getData<DigitalEventSeries>("spikes");
auto trials = dm->getData<DigitalIntervalSeries>("trials");

auto raster = gather(spikes, trials);

// Compute spike counts per trial
auto counts = raster.transform([](auto const& trial) {
    return trial->size();
});

// Access interval metadata
for (size_t i = 0; i < raster.size(); ++i) {
    Interval interval = raster.intervalAt(i);
    // Use raster[i] for the view...
}
```

### Manual View Creation

**Best for:**

- Custom filtering logic not supported by gather()
- When you need fine-grained control over view creation
- Integration with existing code that expects `std::vector<shared_ptr<T>>`

## Alternative Approaches

For specific use cases, consider:

1. **Span-based views**: For contiguous time ranges, return `std::span<TimeFrameIndex>` directly
2. **Index pairs**: For windowed queries, return `(start_idx, end_idx)` into source
3. **Materialized views**: For repeated iteration, call `materialize()` once and reuse

## Running the Benchmark

```bash
# Build
cmake --preset linux-clang-release -DENABLE_BENCHMARK=ON
cmake --build --preset linux-clang-release --target benchmark_RasterPlotViews

# Run all tests
./out/build/Clang/Release/benchmark/benchmark_RasterPlotViews

# Run specific tests
./benchmark_RasterPlotViews --benchmark_filter="FullPipeline"
./benchmark_RasterPlotViews --benchmark_filter="IterationOnly"
./benchmark_RasterPlotViews --benchmark_filter="Gather"
./benchmark_RasterPlotViews --benchmark_filter="ScaleAlignments"

# Cache analysis
perf stat -e cache-references,cache-misses,L1-dcache-load-misses \
    ./benchmark_RasterPlotViews --benchmark_filter="IterationOnly"
```

## Conclusion

The view-based approaches using `DigitalEventSeries` achieve true zero-copy storage sharing via `shared_ptr` with aliasing constructor. The overall overhead is ~3.3x compared to raw vectors, primarily from view object allocation (~1ms for 1000 views) and index indirection during iteration (~1.6x).

**Key findings:**

1. **`gather()` matches or slightly beats manual view creation** - The ~10% improvement at scale comes from better reservation and single-pass interval iteration.

2. **Both view approaches are ~3.3x slower than raw vectors** - This is the expected cost of abstraction (shared_ptr allocations, type erasure, indirection).

3. **`gather()` provides cleaner API with no performance penalty** - You get ergonomic benefits (source tracking, `transform()`, `intervalAt()`) for free.

4. **The `transform()` helper is very fast** - 4µs to compute statistics across 1000 trials.

For most interactive visualization and analysis use cases, the view-based overhead is acceptable. The `gather()` utility is recommended for trial-aligned operations as it provides the cleanest API. For performance-critical rendering loops requiring maximum throughput, raw vectors remain the better choice.
